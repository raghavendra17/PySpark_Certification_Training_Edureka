{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Check the spark.eventLog.dir property\\nevent_log_dir = spark.conf.get(\"spark.eventLog.dir\")\\nprint(\"Spark Event Log Directory:\", event_log_dir)\\nprint(spark.conf.get(\"spark.yarn.resourcemanager.hostname\"))\\nprint(spark.conf.get(\"spark.yarn.resourcemanager.webapp.address\"))'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "os.getcwd()\n",
    "#os.makedirs(\"/home/raghavendr48edu/logs\")\n",
    "\n",
    "#os.makedirs(\"/home/raghavendr48edu/logs\")\n",
    "\n",
    "# Configuration of the Spark Session\n",
    "app_name = \"instacart\"\n",
    "spark = SparkSession.builder \\\n",
    "       .appName(app_name)\\\n",
    "       .config(\"spark.ui.enabled\", \"true\")\\\n",
    "       .config(\"spark.eventLog.enabled\", \"true\")\\\n",
    "       .config(\"spark.eventLog.dir\", \"/home/raghavendr48edu/logs\")\\\n",
    "       .config(\"spark.yarn.resourcemanager.hostname\", \"ip-10-1-1-204.ap-south-1.compute.internal\") \\\n",
    "       .config(\"spark.yarn.resourcemanager.webapp.address\", \"ip-10-1-1-204.ap-south-1.compute.internal:6066\") \\\n",
    "       .config(\"spark.executor.memory\", \"4g\") \\\n",
    "       .config(\"spark.driver.memory\", \"4g\") \\\n",
    "       .getOrCreate()\n",
    "\n",
    "'''# Check the spark.eventLog.dir property\n",
    "event_log_dir = spark.conf.get(\"spark.eventLog.dir\")\n",
    "print(\"Spark Event Log Directory:\", event_log_dir)\n",
    "print(spark.conf.get(\"spark.yarn.resourcemanager.hostname\"))\n",
    "print(spark.conf.get(\"spark.yarn.resourcemanager.webapp.address\"))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local-1685259285241'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_id = spark.sparkContext.applicationId\n",
    "application_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Used: 70336512 bytes\n",
      "Memory Free: 162586284032 bytes\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get the current process ID (assuming it's the Spark driver process)\n",
    "pid = os.getpid()\n",
    "\n",
    "# Retrieve memory usage information\n",
    "memory_info = psutil.Process(pid).memory_info()\n",
    "\n",
    "# Print memory usage details\n",
    "print(f\"Memory Used: {memory_info.rss} bytes\")\n",
    "print(f\"Memory Free: {psutil.virtual_memory().available} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data into Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "| 2539329|      1|   prior|           1|        2|                8|                  null|\n",
      "| 2398795|      1|   prior|           2|        3|                7|                  15.0|\n",
      "|  473747|      1|   prior|           3|        3|               12|                  21.0|\n",
      "| 2254736|      1|   prior|           4|        4|                7|                  29.0|\n",
      "|  431534|      1|   prior|           5|        4|               15|                  28.0|\n",
      "| 3367565|      1|   prior|           6|        2|                7|                  19.0|\n",
      "|  550135|      1|   prior|           7|        1|                9|                  20.0|\n",
      "| 3108588|      1|   prior|           8|        1|               14|                  14.0|\n",
      "| 2295261|      1|   prior|           9|        1|               16|                   0.0|\n",
      "| 2550362|      1|   prior|          10|        4|                8|                  30.0|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----------+--------------------+--------+-------------+\n",
      "|product_id|        product_name|aisle_id|department_id|\n",
      "+----------+--------------------+--------+-------------+\n",
      "|         1|Chocolate Sandwic...|      61|           19|\n",
      "|         2|    All-Seasons Salt|     104|           13|\n",
      "|         3|Robust Golden Uns...|      94|            7|\n",
      "|         4|Smart Ones Classi...|      38|            1|\n",
      "|         5|Green Chile Anyti...|       5|           13|\n",
      "|         6|        Dry Nose Oil|      11|           11|\n",
      "|         7|Pure Coconut Wate...|      98|            7|\n",
      "|         8|Cut Russet Potato...|     116|            1|\n",
      "|         9|Light Strawberry ...|     120|           16|\n",
      "|        10|Sparkling Orange ...|     115|            7|\n",
      "+----------+--------------------+--------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------------+---------------+\n",
      "|department_id|     department|\n",
      "+-------------+---------------+\n",
      "|            1|         frozen|\n",
      "|            2|          other|\n",
      "|            3|         bakery|\n",
      "|            4|        produce|\n",
      "|            5|        alcohol|\n",
      "|            6|  international|\n",
      "|            7|      beverages|\n",
      "|            8|           pets|\n",
      "|            9|dry goods pasta|\n",
      "|           10|           bulk|\n",
      "+-------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------+--------------------+\n",
      "|aisle_id|               aisle|\n",
      "+--------+--------------------+\n",
      "|       1|prepared soups sa...|\n",
      "|       2|   specialty cheeses|\n",
      "|       3| energy granola bars|\n",
      "|       4|       instant foods|\n",
      "|       5|marinades meat pr...|\n",
      "|       6|               other|\n",
      "|       7|       packaged meat|\n",
      "|       8|     bakery desserts|\n",
      "|       9|         pasta sauce|\n",
      "|      10|    kitchen supplies|\n",
      "+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------+----------+-----------------+---------+\n",
      "|order_id|product_id|add_to_cart_order|reordered|\n",
      "+--------+----------+-----------------+---------+\n",
      "|       2|     33120|                1|        1|\n",
      "|       2|     28985|                2|        1|\n",
      "|       2|      9327|                3|        0|\n",
      "|       2|     45918|                4|        1|\n",
      "|       2|     30035|                5|        0|\n",
      "|       2|     17794|                6|        1|\n",
      "|       2|     40141|                7|        1|\n",
      "|       2|      1819|                8|        1|\n",
      "|       2|     43668|                9|        0|\n",
      "|       3|     33754|                1|        1|\n",
      "+--------+----------+-----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------+----------+-----------------+---------+\n",
      "|order_id|product_id|add_to_cart_order|reordered|\n",
      "+--------+----------+-----------------+---------+\n",
      "|       1|     49302|                1|        1|\n",
      "|       1|     11109|                2|        1|\n",
      "|       1|     10246|                3|        0|\n",
      "|       1|     49683|                4|        0|\n",
      "|       1|     43633|                5|        1|\n",
      "|       1|     13176|                6|        0|\n",
      "|       1|     47209|                7|        0|\n",
      "|       1|     22035|                8|        1|\n",
      "|      36|     39612|                1|        0|\n",
      "|      36|     19660|                2|        1|\n",
      "+--------+----------+-----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders = spark.read.csv(\"orders.csv\",inferSchema=True,header=True)\n",
    "products=spark.read.csv(\"products.csv\",inferSchema=True,header=True)\n",
    "departments=spark.read.csv(\"departments.csv\",inferSchema=True,header=True)\n",
    "aisles=spark.read.csv(\"aisles.csv\",inferSchema=True,header=True)\n",
    "order_products__prior=spark.read.csv(\"order_products__prior.csv\",inferSchema=True,header=True)\n",
    "order_products__train=spark.read.csv(\"order_products__train.csv\",inferSchema=True,header=True)\n",
    "\n",
    "orders.createOrReplaceTempView(\"orders\")\n",
    "products.createOrReplaceTempView(\"products\")\n",
    "departments.createOrReplaceTempView(\"departments\")\n",
    "aisles.createOrReplaceTempView(\"aisles\")\n",
    "order_products__prior.createOrReplaceTempView(\"order_products__prior\")\n",
    "order_products__train.createOrReplaceTempView(\"order_products__train\")\n",
    "\n",
    "\n",
    "orders.show(10)\n",
    "products.show(10)\n",
    "departments.show(10)\n",
    "aisles.show(10)\n",
    "order_products__prior.show(10)\n",
    "order_products__train.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3421083, 49688, 21, 134, 32434489, 1384617)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.count(),products.count(),departments.count(),aisles.count(),order_products__prior.count(),order_products__train.count(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT order_id)|\n",
      "+------------------------+\n",
      "|                 3214874|\n",
      "+------------------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT order_id)|\n",
      "+------------------------+\n",
      "|                  131209|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct order_id) from order_products__prior\").show() #3214874\n",
    "spark.sql(\"select count(distinct order_id) from order_products__train\").show() #131209\n",
    "\n",
    "#3421083-(3214874+131209)\n",
    "#75000 records doesn't have product_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking null counts for each column in each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('order_id', 0),\n",
       "  ('user_id', 0),\n",
       "  ('eval_set', 0),\n",
       "  ('order_number', 0),\n",
       "  ('order_dow', 0),\n",
       "  ('order_hour_of_day', 0),\n",
       "  ('days_since_prior_order', 206209)],\n",
       " [('product_id', 0),\n",
       "  ('product_name', 0),\n",
       "  ('aisle_id', 0),\n",
       "  ('department_id', 0)],\n",
       " [('department_id', 0), ('department', 0)],\n",
       " [('aisle_id', 0), ('aisle', 0)],\n",
       " [('order_id', 0),\n",
       "  ('product_id', 0),\n",
       "  ('add_to_cart_order', 0),\n",
       "  ('reordered', 0)],\n",
       " [('order_id', 0),\n",
       "  ('product_id', 0),\n",
       "  ('add_to_cart_order', 0),\n",
       "  ('reordered', 0)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names = ['orders', 'products', 'departments', 'aisles', 'order_products__prior', 'order_products__train']\n",
    "null_counts = [\n",
    "    [(col, df.where(df[col].isNull()).count()) for col in df.columns]\n",
    "    for df_name in df_names\n",
    "    for df in [globals()[df_name]]\n",
    "]\n",
    "'''\n",
    "# Print the results\n",
    "for i, df_name in enumerate(df_names):\n",
    "    print(f\"Null counts in DataFrame '{df_name}':\")\n",
    "    for col, count in null_counts[i]:\n",
    "        print(f\"{col}: {count}\")\n",
    "    print()\n",
    "    '''\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merge all the data frames based on the common key and create a single DataFrame and 3. check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+------------+----------+--------------------+------------+\n",
      "|department_id|aisle_id|       aisle|product_id|        product_name|  department|\n",
      "+-------------+--------+------------+----------+--------------------+------------+\n",
      "|           12|     122|meat counter|       175|        T Bone Steak|meat seafood|\n",
      "|           12|     122|meat counter|       194|      Lamb Rib Chops|meat seafood|\n",
      "|           12|     122|meat counter|       692|         Skirt Steak|meat seafood|\n",
      "|           12|     122|meat counter|      1938|      Beef Stew Meat|meat seafood|\n",
      "|           12|     122|meat counter|      2301|Beef Loin Porterh...|meat seafood|\n",
      "+-------------+--------+------------+----------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_merge = aisles.join(products, \"aisle_id\",\"outer\").join(departments, \"department_id\",\"outer\")\n",
    "df_merge.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49688"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-----+----------+------------+----------+\n",
      "|department_id|aisle_id|aisle|product_id|product_name|department|\n",
      "+-------------+--------+-----+----------+------------+----------+\n",
      "|            0|       0|    1|         0|           0|         1|\n",
      "+-------------+--------+-----+----------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, isnull, isnan, sum\n",
    "\n",
    "null_counts = df_merge.select([sum(col(column).isNull().cast(\"int\")).alias(column) for column in df_merge.columns])\n",
    "null_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-----+----------+--------------------+----------+\n",
      "|department_id|aisle_id|aisle|product_id|        product_name|department|\n",
      "+-------------+--------+-----+----------+--------------------+----------+\n",
      "|         Red\"| Blunted| null|      6816|\"Scotch Kids 5\"\" ...|      null|\n",
      "+-------------+--------+-----+----------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "# Create a list comprehension to generate the condition for each column\n",
    "null_conditions = [col(column).isNull() for column in df_merge.columns]\n",
    "# Apply the conditions using the OR operator to filter the dataframe\n",
    "null_records = df_merge.filter(reduce(lambda a, b: a | b, null_conditions))\n",
    "# Display the null records\n",
    "null_records.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+-------------+\n",
      "|product_id|        product_name|aisle_id|department_id|\n",
      "+----------+--------------------+--------+-------------+\n",
      "|      6816|\"Scotch Kids 5\"\" ...| Blunted|         Red\"|\n",
      "+----------+--------------------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products[products['product_id']==6816].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------+\n",
      "|order_id|product_id|add_to_cart_order|reordered|\n",
      "+--------+----------+-----------------+---------+\n",
      "|  482604|      6816|                8|        0|\n",
      "| 1776850|      6816|                3|        0|\n",
      "| 2662328|      6816|                8|        0|\n",
      "+--------+----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_products__prior[order_products__prior['product_id']==6816].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------+\n",
      "|order_id|product_id|add_to_cart_order|reordered|\n",
      "+--------+----------+-----------------+---------+\n",
      "+--------+----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_products__train[order_products__train['product_id']==6816].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* For 3 records product_id=6816 aisle_id,department_id is not there but there are 3 records in order.\n",
    "* let us keep in mind and drop if necessary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_merge=df_merge.filter(df_merge['product_id']!=6816)\n",
    "df_merge.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|order_id|\n",
      "+--------+\n",
      "|       6|\n",
      "|       3|\n",
      "|       5|\n",
      "|       9|\n",
      "|       4|\n",
      "|       8|\n",
      "|       7|\n",
      "|       2|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|order_id|\n",
      "+--------+\n",
      "|       1|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_products__prior[(order_products__prior[\"order_id\"]>0) & (order_products__prior[\"order_id\"]<10)].select(\"order_id\").distinct().show()\n",
    "order_products__train[(order_products__train[\"order_id\"]>0) & (order_products__train[\"order_id\"]<10)].select(\"order_id\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|distinct_count|\n",
      "+--------------+\n",
      "|       3346083|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order_products=order_products__prior.union(order_products__train)\n",
    "#df_order_products.select(\"order_id\").distinct().count()\n",
    "df_order_products.agg(F.countDistinct(\"order_id\").alias(\"distinct_count\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33819106"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_order_products.count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.files.maxOpenFiles\", \"400000000\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### limit is used to control too many open files error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33894106"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_outer=orders.limit(350000000).join(df_order_products.limit(350000000),\"order_id\",\"outer\")\n",
    "df_orders_outer.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+------------+---------+-----------------+----------------------+----------+-----------------+---------+\n",
      "|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|product_id|add_to_cart_order|reordered|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+----------+-----------------+---------+\n",
      "|       0|      0|       0|           0|        0|                0|               2078068|     75000|            75000|    75000|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_counts = df_orders_outer.select([sum(col(column).isNull().cast(\"int\")).alias(column) for column in df_orders_outer.columns])\n",
    "# Display the null counts\n",
    "null_counts.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 75000 orders has no details of productId,add_to_cart_order, reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------+------------+---------+-----------------+----------------------+-----------------+---------+-------------+--------+------------+------------+----------+\n",
      "|product_id|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|add_to_cart_order|reordered|department_id|aisle_id|       aisle|product_name|department|\n",
      "+----------+--------+-------+--------+------------+---------+-----------------+----------------------+-----------------+---------+-------------+--------+------------+------------+----------+\n",
      "|       148|     224| 109534|   prior|           6|        0|               14|                  13.0|                2|        1|            4|      24|fresh fruits|  Nectarines|   produce|\n",
      "|       148|    1452|  72231|   prior|          16|        2|               22|                  15.0|                5|        1|            4|      24|fresh fruits|  Nectarines|   produce|\n",
      "|       148|    2688|  99750|   prior|          17|        6|               22|                   5.0|                8|        0|            4|      24|fresh fruits|  Nectarines|   produce|\n",
      "|       148|    2908| 156422|   prior|           5|        2|               14|                  15.0|               15|        1|            4|      24|fresh fruits|  Nectarines|   produce|\n",
      "|       148|    3560|  57970|   prior|           3|        4|                5|                  26.0|                6|        0|            4|      24|fresh fruits|  Nectarines|   produce|\n",
      "+----------+--------+-------+--------+------------+---------+-----------------+----------------------+-----------------+---------+-------------+--------+------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_orders_outer.join(df_merge,'product_id','outer')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33894109"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------+------------+---------+-----------------+----------------------+-----------------+---------+-------------+--------+-----+--------------------+----------+\n",
      "|product_id|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|add_to_cart_order|reordered|department_id|aisle_id|aisle|        product_name|department|\n",
      "+----------+--------+-------+--------+------------+---------+-----------------+----------------------+-----------------+---------+-------------+--------+-----+--------------------+----------+\n",
      "|      6816|  482604|  16340|   prior|          51|        4|               11|                   2.0|                8|        0|         Red\"| Blunted| null|\"Scotch Kids 5\"\" ...|      null|\n",
      "|      6816| 1776850| 120158|   prior|          14|        4|               22|                   6.0|                3|        0|         Red\"| Blunted| null|\"Scotch Kids 5\"\" ...|      null|\n",
      "|      6816| 2662328|  72754|   prior|           6|        5|               21|                   3.0|                8|        0|         Red\"| Blunted| null|\"Scotch Kids 5\"\" ...|      null|\n",
      "+----------+--------+-------+--------+------------+---------+-----------------+----------------------+-----------------+---------+-------------+--------+-----+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[df['product_id']==6816].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* above are 3 extra records. Total 75003 null records due to outer join  except days_since_prior_order column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.List the most ordered products (top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+\n",
      "|product_id|        product_name| count|\n",
      "+----------+--------------------+------+\n",
      "|     24852|              Banana|491291|\n",
      "|     13176|Bag of Organic Ba...|394930|\n",
      "|     21137|Organic Strawberries|275577|\n",
      "|     21903|Organic Baby Spinach|251705|\n",
      "|     47209|Organic Hass Avocado|220877|\n",
      "|     47766|     Organic Avocado|184224|\n",
      "|     47626|         Large Lemon|160792|\n",
      "|     16797|        Strawberries|149445|\n",
      "|     26209|               Limes|146660|\n",
      "|     27845|  Organic Whole Milk|142813|\n",
      "+----------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('product_id','product_name').count().orderBy(col('count').desc()).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+----+\n",
      "|product_id|        product_name| count|rank|\n",
      "+----------+--------------------+------+----+\n",
      "|     24852|              Banana|491291|   1|\n",
      "|     13176|Bag of Organic Ba...|394930|   2|\n",
      "|     21137|Organic Strawberries|275577|   3|\n",
      "|     21903|Organic Baby Spinach|251705|   4|\n",
      "|     47209|Organic Hass Avocado|220877|   5|\n",
      "|     47766|     Organic Avocado|184224|   6|\n",
      "|     47626|         Large Lemon|160792|   7|\n",
      "|     16797|        Strawberries|149445|   8|\n",
      "|     26209|               Limes|146660|   9|\n",
      "|     27845|  Organic Whole Milk|142813|  10|\n",
      "|     27966| Organic Raspberries|142603|  11|\n",
      "|     22935|Organic Yellow Onion|117716|  12|\n",
      "|     24964|      Organic Garlic|113936|  13|\n",
      "|     45007|    Organic Zucchini|109412|  14|\n",
      "|     39275| Organic Blueberries|105026|  15|\n",
      "|     49683|      Cucumber Kirby| 99728|  16|\n",
      "|     28204|  Organic Fuji Apple| 92889|  17|\n",
      "|      5876|       Organic Lemon| 91251|  18|\n",
      "|     40706|Organic Grape Tom...| 88078|  19|\n",
      "|      8277|Apple Honeycrisp ...| 87272|  20|\n",
      "+----------+--------------------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, rank, count,dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df.withColumn('count', count('product_id').over(Window.partitionBy('product_id'))) \\\n",
    "                 .withColumn('rank', dense_rank().over(Window.orderBy(col('count').desc()))) \\\n",
    "                 .select('product_id', 'product_name', 'count','rank').distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"Instacart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+\n",
      "|product_id|        product_name| count|\n",
      "+----------+--------------------+------+\n",
      "|     24852|              Banana|491291|\n",
      "|     13176|Bag of Organic Ba...|394930|\n",
      "|     21137|Organic Strawberries|275577|\n",
      "|     21903|Organic Baby Spinach|251705|\n",
      "|     47209|Organic Hass Avocado|220877|\n",
      "|     47766|     Organic Avocado|184224|\n",
      "|     47626|         Large Lemon|160792|\n",
      "|     16797|        Strawberries|149445|\n",
      "|     26209|               Limes|146660|\n",
      "|     27845|  Organic Whole Milk|142813|\n",
      "+----------+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select distinct product_id,product_name,count(product_id) OVER(partition by product_id) as count from Instacart order by count desc\").show(10)\n",
    "#spark.sql(\"select distinct product_id,product_name,count(product_id) OVER(partition by product_id order by count(product_id) desc) as count from Instacart \").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Do people usually reorder the same previous ordered products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------------+----------------------+\n",
      "|product_id|count|sum_reordered|reordering_probability|\n",
      "+----------+-----+-------------+----------------------+\n",
      "|      6433|   69|           65|    0.9420289855072463|\n",
      "|      2075|   90|           84|    0.9333333333333333|\n",
      "|     43553|   13|           12|    0.9230769230769231|\n",
      "|     27740|  102|           94|    0.9215686274509803|\n",
      "|     14609|   35|           32|    0.9142857142857143|\n",
      "|     13875|   45|           41|    0.9111111111111111|\n",
      "|     39992|   22|           20|    0.9090909090909091|\n",
      "|      5868|   30|           27|                   0.9|\n",
      "|     36543|   69|           62|    0.8985507246376812|\n",
      "|     26093|   67|           60|    0.8955223880597015|\n",
      "|      4212|   38|           34|    0.8947368421052632|\n",
      "|     35604|  104|           93|    0.8942307692307693|\n",
      "|     38438|   28|           25|    0.8928571428571429|\n",
      "|     38251|  111|           99|    0.8918918918918919|\n",
      "|     36801|   99|           88|    0.8888888888888888|\n",
      "|     31418|   62|           55|    0.8870967741935484|\n",
      "|     38529|   42|           37|    0.8809523809523809|\n",
      "|     47825|   25|           22|                  0.88|\n",
      "|     25766|   32|           28|                 0.875|\n",
      "|     14725|   31|           27|    0.8709677419354839|\n",
      "+----------+-----+-------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"product_id\")\n",
    "df.withColumn(\"count\", F.count(\"product_id\").over(windowSpec)) \\\n",
    "           .withColumn(\"sum_reordered\", F.sum(\"reordered\").over(windowSpec)) \\\n",
    "           .select(\"product_id\", \"count\", \"sum_reordered\") \\\n",
    "           .distinct().withColumn(\"reordering_probability\",F.col(\"sum_reordered\")/F.col(\"count\")) \\\n",
    "            .orderBy(F.desc(\"reordering_probability\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------------+----------------------+\n",
      "|product_id|count|sum_reordered|reordering_probability|\n",
      "+----------+-----+-------------+----------------------+\n",
      "|      6433|   69|           65|    0.9420289855072463|\n",
      "|      2075|   90|           84|    0.9333333333333333|\n",
      "|     43553|   13|           12|    0.9230769230769231|\n",
      "|     27740|  102|           94|    0.9215686274509803|\n",
      "|     14609|   35|           32|    0.9142857142857143|\n",
      "|     13875|   45|           41|    0.9111111111111111|\n",
      "|     39992|   22|           20|    0.9090909090909091|\n",
      "|      5868|   30|           27|                   0.9|\n",
      "|     36543|   69|           62|    0.8985507246376812|\n",
      "|     26093|   67|           60|    0.8955223880597015|\n",
      "|      4212|   38|           34|    0.8947368421052632|\n",
      "|     35604|  104|           93|    0.8942307692307693|\n",
      "|     38438|   28|           25|    0.8928571428571429|\n",
      "|     38251|  111|           99|    0.8918918918918919|\n",
      "|     36801|   99|           88|    0.8888888888888888|\n",
      "|     31418|   62|           55|    0.8870967741935484|\n",
      "|     38529|   42|           37|    0.8809523809523809|\n",
      "|     47825|   25|           22|                  0.88|\n",
      "|     25766|   32|           28|                 0.875|\n",
      "|      2406|   31|           27|    0.8709677419354839|\n",
      "+----------+-----+-------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"product_id\") \\\n",
    "           .agg(F.count(\"product_id\").alias(\"count\"), \\\n",
    "                F.sum(\"reordered\").alias(\"sum_reordered\")) \\\n",
    "            .withColumn(\"reordering_probability\",F.col(\"sum_reordered\")/F.col(\"count\")) \\\n",
    "            .orderBy(F.desc(\"reordering_probability\")).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using groupBy and agg in this way is a more efficient approach for this particular task compared to using window functions. Window functions are generally useful when you need to perform calculations over a window of rows based on a specific ordering or partitioning. In this case, since you want to calculate aggregate values grouped by product_id, groupBy and agg are better suited for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------+----------------------+\n",
      "|product_id|count(product_id)|sum(reordered)|reordering_probability|\n",
      "+----------+-----------------+--------------+----------------------+\n",
      "|      6433|               69|            65|    0.9420289855072463|\n",
      "|      2075|               90|            84|    0.9333333333333333|\n",
      "|     43553|               13|            12|    0.9230769230769231|\n",
      "|     27740|              102|            94|    0.9215686274509803|\n",
      "|     14609|               35|            32|    0.9142857142857143|\n",
      "|     13875|               45|            41|    0.9111111111111111|\n",
      "|     39992|               22|            20|    0.9090909090909091|\n",
      "|      5868|               30|            27|                   0.9|\n",
      "|     36543|               69|            62|    0.8985507246376812|\n",
      "|     26093|               67|            60|    0.8955223880597015|\n",
      "+----------+-----------------+--------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select product_id,count(product_id),sum(reordered),sum(reordered)/count(product_id) as reordering_probability from Instacart\\\n",
    "          group by product_id order by reordering_probability desc\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------------+----------------------+\n",
      "|product_id|count|sum_reordered|reordering_probability|\n",
      "+----------+-----+-------------+----------------------+\n",
      "|      6433|   69|           65|    0.9420289855072463|\n",
      "|      2075|   90|           84|    0.9333333333333333|\n",
      "|     43553|   13|           12|    0.9230769230769231|\n",
      "|     27740|  102|           94|    0.9215686274509803|\n",
      "|     14609|   35|           32|    0.9142857142857143|\n",
      "|     13875|   45|           41|    0.9111111111111111|\n",
      "|     39992|   22|           20|    0.9090909090909091|\n",
      "|      5868|   30|           27|                   0.9|\n",
      "|     36543|   69|           62|    0.8985507246376812|\n",
      "|     26093|   67|           60|    0.8955223880597015|\n",
      "+----------+-----+-------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT distinct product_id, COUNT(product_id) OVER (PARTITION BY product_id) AS count, \\\n",
    "                   SUM(reordered) OVER (PARTITION BY product_id) AS sum_reordered, \\\n",
    "                   SUM(reordered) OVER (PARTITION BY product_id) / COUNT(product_id) OVER (PARTITION BY product_id) AS reordering_probability \\\n",
    "                   FROM Instacart \\\n",
    "                   ORDER BY reordering_probability DESC \\\n",
    "                   LIMIT 10\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|reordering_sentiment|\n",
      "+--------------------+\n",
      "|  0.3664610156232542|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Overall mean of the reordering probability will decide the overall attitude of public in reordering\n",
    "\n",
    "spark.sql('Select avg(a.reordering_probability) as reordering_sentiment from \\\n",
    "          (Select product_id ,count(product_id) as purchase_count , sum(reordered) as reorderd_count , \\\n",
    "          sum(reordered)/count(product_id) as reordering_probability  from order_products__prior \\\n",
    "          group by product_id  order by reordering_probability desc) as a').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.List most reordered products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------+\n",
      "|product_id|        product_name|sum(reordered)|\n",
      "+----------+--------------------+--------------+\n",
      "|     24852|              Banana|        415166|\n",
      "|     13176|Bag of Organic Ba...|        329275|\n",
      "|     21137|Organic Strawberries|        214448|\n",
      "|     21903|Organic Baby Spinach|        194939|\n",
      "|     47209|Organic Hass Avocado|        176173|\n",
      "|     47766|     Organic Avocado|        140270|\n",
      "|     27845|  Organic Whole Milk|        118684|\n",
      "|     47626|         Large Lemon|        112178|\n",
      "|     27966| Organic Raspberries|        109688|\n",
      "|     16797|        Strawberries|        104588|\n",
      "+----------+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select product_id,product_name,sum(reordered) from Instacart group by product_id,product_name order by sum(reordered) desc\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|product_id|sum_reordered|\n",
      "+----------+-------------+\n",
      "|     24852|       415166|\n",
      "|     13176|       329275|\n",
      "|     21137|       214448|\n",
      "|     21903|       194939|\n",
      "|     47209|       176173|\n",
      "|     47766|       140270|\n",
      "|     27845|       118684|\n",
      "|     47626|       112178|\n",
      "|     27966|       109688|\n",
      "|     16797|       104588|\n",
      "+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('product_id').agg(F.sum('reordered').alias(\"sum_reordered\")).orderBy(F.desc('sum_reordered')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Most important department and aisle (by number of products) and 8.Get the Top 10 departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|department_id|count(product_id)|\n",
      "+-------------+-----------------+\n",
      "|           11|             6563|\n",
      "|           19|             6264|\n",
      "|           13|             5371|\n",
      "|            7|             4365|\n",
      "|            1|             4007|\n",
      "|           16|             3449|\n",
      "|           17|             3084|\n",
      "|           15|             2092|\n",
      "|            9|             1858|\n",
      "|            4|             1684|\n",
      "+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Select department_id,count(product_id)  from products group by department_id  order by count(product_id)  desc limit 10\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|department_id|count_product|\n",
      "+-------------+-------------+\n",
      "|           11|         6563|\n",
      "|           19|         6264|\n",
      "|           13|         5371|\n",
      "|            7|         4365|\n",
      "|            1|         4007|\n",
      "|           16|         3449|\n",
      "|           17|         3084|\n",
      "|           15|         2092|\n",
      "|            9|         1858|\n",
      "|            4|         1684|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT distinct department_id, count(product_id) over (PARTITION BY department_id) as count_product FROM products \\\n",
    "            order by count_product desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+-------------+\n",
      "|department_id|     department|count_product|\n",
      "+-------------+---------------+-------------+\n",
      "|           11|  personal care|         6563|\n",
      "|           19|         snacks|         6264|\n",
      "|           13|         pantry|         5371|\n",
      "|            7|      beverages|         4365|\n",
      "|            1|         frozen|         4007|\n",
      "|           16|     dairy eggs|         3449|\n",
      "|           17|      household|         3084|\n",
      "|           15|   canned goods|         2092|\n",
      "|            9|dry goods pasta|         1858|\n",
      "|            4|        produce|         1684|\n",
      "+-------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT p.department_id, d.department, count_product \\\n",
    "           FROM (SELECT department_id, COUNT(product_id) AS count_product \\\n",
    "                 FROM products \\\n",
    "                 GROUP BY department_id) p \\\n",
    "           JOIN departments d ON p.department_id = d.department_id \\\n",
    "           ORDER BY count_product DESC \\\n",
    "           LIMIT 10\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+-------------+\n",
      "|department_id|     department|count_product|\n",
      "+-------------+---------------+-------------+\n",
      "|           11|  personal care|         6563|\n",
      "|           19|         snacks|         6264|\n",
      "|           13|         pantry|         5371|\n",
      "|            7|      beverages|         4365|\n",
      "|            1|         frozen|         4007|\n",
      "|           16|     dairy eggs|         3449|\n",
      "|           17|      household|         3084|\n",
      "|           15|   canned goods|         2092|\n",
      "|            9|dry goods pasta|         1858|\n",
      "|            4|        produce|         1684|\n",
      "+-------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT p.department_id, d.department, COUNT(p.product_id) AS count_product \\\n",
    "           FROM products p \\\n",
    "           JOIN departments d ON p.department_id = d.department_id \\\n",
    "           GROUP BY p.department_id, d.department \\\n",
    "           ORDER BY count_product DESC \\\n",
    "           LIMIT 10\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+-------------+\n",
      "|department_id|     department|count_product|\n",
      "+-------------+---------------+-------------+\n",
      "|           11|  personal care|         6563|\n",
      "|           19|         snacks|         6264|\n",
      "|           13|         pantry|         5371|\n",
      "|            7|      beverages|         4365|\n",
      "|            1|         frozen|         4007|\n",
      "|           16|     dairy eggs|         3449|\n",
      "|           17|      household|         3084|\n",
      "|           15|   canned goods|         2092|\n",
      "|            9|dry goods pasta|         1858|\n",
      "|            4|        produce|         1684|\n",
      "|            3|         bakery|         1516|\n",
      "|           20|           deli|         1322|\n",
      "|           21|        missing|         1258|\n",
      "|            6|  international|         1139|\n",
      "|           14|      breakfast|         1115|\n",
      "|           18|         babies|         1081|\n",
      "|            5|        alcohol|         1054|\n",
      "|            8|           pets|          972|\n",
      "|           12|   meat seafood|          907|\n",
      "|            2|          other|          548|\n",
      "|           10|           bulk|           38|\n",
      "|         Red\"|           null|            1|\n",
      "|         null|           null|            0|\n",
      "+-------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('department_id','department','product_id').groupby('department_id','department').agg(F.countDistinct('product_id').alias('count_product')).orderBy(F.desc('count_product')).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.List top 10 products ordered in the morning (6 AM to 11 AM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+\n",
      "|product_id|        product_name| count|\n",
      "+----------+--------------------+------+\n",
      "|     24852|              Banana|169965|\n",
      "|     13176|Bag of Organic Ba...|135417|\n",
      "|     21137|Organic Strawberries| 92499|\n",
      "|     21903|Organic Baby Spinach| 82578|\n",
      "|     47209|Organic Hass Avocado| 72545|\n",
      "|     47766|     Organic Avocado| 59603|\n",
      "|     47626|         Large Lemon| 53479|\n",
      "|     16797|        Strawberries| 52155|\n",
      "|     27966| Organic Raspberries| 49751|\n",
      "|     27845|  Organic Whole Milk| 49747|\n",
      "+----------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((col('order_hour_of_day')>=6) & (col('order_hour_of_day')<=11)).groupby('product_id','product_name').count().orderBy(col('count').desc()).limit(10).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
