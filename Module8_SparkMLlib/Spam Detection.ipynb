{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"SpamDetection\").config(\"spark.ui.enabled\", \"true\")\\\n",
    "       .config(\"spark.eventLog.enabled\", \"true\")\\\n",
    "       .config(\"spark.eventLog.dir\", \"/home/raghavendr48edu/logs\")\\\n",
    "       .config(\"spark.yarn.resourcemanager.hostname\", \"ip-10-1-1-204.ap-south-1.compute.internal\") \\\n",
    "       .config(\"spark.yarn.resourcemanager.webapp.address\", \"ip-10-1-1-204.ap-south-1.compute.internal:6066\") \\\n",
    "       .config(\"spark.executor.memory\", \"4g\") \\\n",
    "       .config(\"spark.driver.memory\", \"4g\") \\\n",
    "       .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get headers using withColumnRenamed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataframe = spark.read.option(\"delimiter\",'\\t').option(\"inferSchema\",True).csv(\"SMSSpamCollection\")\n",
    "\n",
    "headers = [\"spam\",\"message\"]  # Replace with your column names\n",
    "\n",
    "# Rename the columns\n",
    "for i, header in enumerate(headers):\n",
    "    dataframe = dataframe.withColumnRenamed(\"_c{}\".format(i), header)\n",
    "\n",
    "# Show the contents of the DataFrame\n",
    "dataframe.show(5)\n",
    "\n",
    "+----+--------------------+\n",
    "|spam|             message|\n",
    "+----+--------------------+\n",
    "| ham|Go until jurong p...|\n",
    "| ham|Ok lar... Joking ...|\n",
    "|spam|Free entry in 2 a...|\n",
    "| ham|U dun say so earl...|\n",
    "| ham|Nah I don't think...|\n",
    "+----+--------------------+\n",
    "\n",
    "df = df.withColumn(\"words\",F.split(df.message, \"\\\\s+\"))\n",
    "\n",
    "# Show the contents of the DataFrame\n",
    "df.show(5)\n",
    "+----+--------------------+--------------------+\n",
    "|spam|             message|               words|\n",
    "+----+--------------------+--------------------+\n",
    "| ham|Go until jurong p...|[Go, until, juron...|\n",
    "| ham|Ok lar... Joking ...|[Ok, lar..., Joki...|\n",
    "|spam|Free entry in 2 a...|[Free, entry, in,...|\n",
    "| ham|U dun say so earl...|[U, dun, say, so,...|\n",
    "| ham|Nah I don't think...|[Nah, I, don't, t...|\n",
    "+----+--------------------+--------------------+\n",
    "only showing top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get headers by converting to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|spam|             message|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- spam: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n",
      "+----+--------------------+------+\n",
      "|spam|             message|length|\n",
      "+----+--------------------+------+\n",
      "| ham|Go until jurong p...|   111|\n",
      "| ham|Ok lar... Joking ...|    29|\n",
      "|spam|Free entry in 2 a...|   155|\n",
      "| ham|U dun say so earl...|    49|\n",
      "| ham|Nah I don't think...|    61|\n",
      "+----+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+-----------------+\n",
      "|spam|      avg(length)|\n",
      "+----+-----------------+\n",
      "| ham|71.45431945307645|\n",
      "|spam|138.6706827309237|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''headers = [\"header1\", \"header2\", \"header3\"]  # Replace with your column names\n",
    "dataframe = dataframe.toDF(*headers)'''\n",
    "df=spark.read.option(\"delimiter\",\"\\t\").csv(\"SMSSpamCollection\").toDF(\"spam\",\"message\")\n",
    "df.show(5)\n",
    "df.printSchema()\n",
    "df=df.withColumn(\"length\",F.length(df['message']))\n",
    "df.show(5)\n",
    "df.groupBy('spam').mean().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spam messages has higher length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "* 1.Extract the word\n",
    "* 2.Removed stop words. \n",
    "* 3.Modify the stop words to include your custom words such as ‘-‘\n",
    "* 4.Create the features from SMS message using CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|spam|             message|length|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
      "+----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(13423,[7,11,31,6...|(13424,[7,11,31,6...|\n",
      "| ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,297,...|(13423,[0,24,297,...|(13424,[0,24,297,...|\n",
      "|spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(13423,[2,13,19,3...|(13424,[2,13,19,3...|\n",
      "| ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(13423,[0,70,80,1...|(13424,[0,70,80,1...|\n",
      "| ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|(13423,[36,134,31...|(13424,[36,134,31...|\n",
      "+----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover,CountVectorizer,IDF,StringIndexer,VectorAssembler\n",
    "\n",
    "tokenizer=Tokenizer(inputCol=\"message\",outputCol=\"token_text\")\n",
    "stop_word_remover=StopWordsRemover(inputCol=\"token_text\",outputCol=\"stop_tokens\")\n",
    "#stopwords = StopWordsRemover().getStopWords() + [\"-\"] less accuracy on having this\n",
    "#stop_word_remover = StopWordsRemover().setStopWords(stopwords).setInputCol(\"token_text\").setOutputCol(\"stop_tokens\")\n",
    "count_vec=CountVectorizer(inputCol=\"stop_tokens\",outputCol=\"c_vec\") # you can use hashdocumentfrequency\n",
    "idf=IDF(inputCol=\"c_vec\",outputCol=\"tf_idf\")\n",
    "ham_spam_to_num=StringIndexer(inputCol=\"spam\",outputCol=\"label\")\n",
    "cleaned=VectorAssembler(inputCols=['tf_idf','length'],outputCol=\"features\")\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline=Pipeline(stages=[ham_spam_to_num,tokenizer,stop_word_remover,count_vec,idf,cleaned])\n",
    "cleaner=pipeline.fit(df)\n",
    "clean_df=cleaner.transform(df)\n",
    "clean_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### CountVectorizer Vocabulary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clean_df.select('stop_tokens').take(1)\n",
    "[Row(stop_tokens=['go', 'jurong', 'point,', 'crazy..', 'available', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet...', 'cine', 'got', 'amore', 'wat...'])]\n",
    "\n",
    "cleaner.stages\n",
    "[StringIndexerModel: uid=StringIndexer_0a26754b8f2b, handleInvalid=error,\n",
    " Tokenizer_865bfefd836a,\n",
    " StopWordsRemover_781aa9b60d35,\n",
    " CountVectorizerModel: uid=CountVectorizer_42e8971891c9, vocabularySize=13423,\n",
    " IDFModel: uid=IDF_39a215e64e56, numDocs=5574, numFeatures=13423,\n",
    " VectorAssembler_e2392c263028]\n",
    " \n",
    " cleaner.stages[3].vocabulary\n",
    "#if you observe 7 index is go\n",
    "['u',\n",
    " 'call',\n",
    " '2',\n",
    " '',\n",
    " 'ur',\n",
    " 'get',\n",
    " '&lt;#&gt;',\n",
    " 'go',\n",
    " '4',\n",
    " '.',\n",
    " 'like',\n",
    " 'got',\n",
    " 'know',\n",
    " 'free',\n",
    " 'come',\n",
    " 'good',\n",
    " '?',\n",
    " 'send',..]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorization , TFIDF , VectorAssembler o/p's"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "clean_df.select('c_vec').take(1)\n",
    "[Row(c_vec=SparseVector(13423, {7: 1.0, 11: 1.0, 31: 1.0, 61: 1.0, 72: 1.0, 344: 1.0, 625: 1.0, 731: 1.0, 1409: 1.0, 1598: 1.0, 4485: 1.0, 6440: 1.0, 8092: 1.0, 8838: 1.0, 11344: 1.0, 12979: 1.0}))]\n",
    "\n",
    "clean_df.select('tf_idf').take(1)\n",
    "[Row(tf_idf=SparseVector(13423, {7: 3.1126, 11: 3.2055, 31: 3.822, 61: 4.2072, 72: 4.322, 344: 5.4072, 625: 5.918, 731: 6.1411, 1409: 6.6801, 1598: 6.8343, 4485: 7.5274, 6440: 7.9329, 8092: 7.9329, 8838: 7.9329, 11344: 7.9329, 12979: 7.9329}))]\n",
    "\n",
    "clean_df.select('features').take(2)\n",
    "[Row(features=SparseVector(13424, {7: 3.1126, 11: 3.2055, 31: 3.822, 61: 4.2072, 72: 4.322, 344: 5.4072, 625: 5.918, 731: 6.1411, 1409: 6.6801, 1598: 6.8343, 4485: 7.5274, 6440: 7.9329, 8092: 7.9329, 8838: 7.9329, 11344: 7.9329, 12979: 7.9329, 13423: 111.0})),\n",
    " Row(features=SparseVector(13424, {0: 2.0167, 24: 3.5762, 297: 5.3302, 457: 5.7357, 2601: 7.2398, 3605: 7.5274, 13423: 29.0})),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test -decide on a strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(13424,[0,1,2,41,...|[-1060.7325420854...|[1.0,9.6391158107...|       0.0|\n",
      "|  0.0|(13424,[0,1,5,20,...|[-803.13623340156...|[1.0,2.7071860143...|       0.0|\n",
      "|  0.0|(13424,[0,1,7,8,1...|[-1152.0926413349...|[1.0,6.3682506790...|       0.0|\n",
      "|  0.0|(13424,[0,1,7,15,...|[-656.71821333935...|[1.0,7.6641099247...|       0.0|\n",
      "|  0.0|(13424,[0,1,12,33...|[-444.22584589378...|[1.0,1.4534997554...|       0.0|\n",
      "|  0.0|(13424,[0,1,14,18...|[-1361.3769955108...|[1.0,3.0750315514...|       0.0|\n",
      "|  0.0|(13424,[0,1,14,31...|[-215.48901780946...|[1.0,4.5987538642...|       0.0|\n",
      "|  0.0|(13424,[0,1,18,20...|[-839.83426960294...|[1.0,9.2487549816...|       0.0|\n",
      "|  0.0|(13424,[0,1,21,27...|[-757.86523084176...|[1.0,1.0965819687...|       0.0|\n",
      "|  0.0|(13424,[0,1,23,63...|[-1311.7973080045...|[1.0,1.2626900742...|       0.0|\n",
      "|  0.0|(13424,[0,1,24,31...|[-338.17254100552...|[1.0,6.3355918240...|       0.0|\n",
      "|  0.0|(13424,[0,1,31,43...|[-339.83341572864...|[1.0,6.8011431288...|       0.0|\n",
      "|  0.0|(13424,[0,1,43,69...|[-618.15808035325...|[0.99912875455213...|       0.0|\n",
      "|  0.0|(13424,[0,1,46,17...|[-1140.5200030944...|[2.04665760524485...|       1.0|\n",
      "|  0.0|(13424,[0,1,146,1...|[-253.92027337846...|[0.33435758341802...|       1.0|\n",
      "|  0.0|(13424,[0,1,498,5...|[-319.75375823925...|[0.99999999999983...|       0.0|\n",
      "|  0.0|(13424,[0,1,874,1...|[-98.630364614541...|[0.99999966720666...|       0.0|\n",
      "|  0.0|(13424,[0,2,3,5,6...|[-2591.6096716023...|[1.0,8.5241831496...|       0.0|\n",
      "|  0.0|(13424,[0,2,3,6,9...|[-3410.7364205531...|[1.0,1.5299127223...|       0.0|\n",
      "|  0.0|(13424,[0,2,3,6,9...|[-3410.7364205531...|[1.0,1.5299127223...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df=clean_df.select(['label','features'])\n",
    "(train,test)=clean_df.randomSplit([0.7,0.3],seed=42)\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb=NaiveBayes()\n",
    "pred=nb.fit(train)\n",
    "res=pred.transform(test)\n",
    "res.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestFeatures, RawPredictions( extracted from classProbabilities,FeatureProbabilities)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test.select('features').take(2)\n",
    "[Row(features=SparseVector(13424, {0: 2.0167, 1: 2.3646, 2: 2.7045, 41: 3.9256, 171: 4.9125, 172: 4.9372, 217: 5.1295, 308: 5.3302, 611: 5.918, 1725: 6.8343, 2285: 7.0166, 2966: 7.2398, 3224: 7.2398, 8373: 7.9329, 9368: 7.9329, 9413: 7.9329, 11655: 7.9329, 13423: 103.0})),\n",
    " Row(features=SparseVector(13424, {0: 6.0501, 1: 2.3646, 5: 2.7511, 20: 3.5323, 48: 3.9913, 54: 4.0513, 78: 4.3634, 83: 4.4364, 386: 5.5815, 495: 5.7928, 623: 5.918, 949: 6.3235, 977: 6.3235, 1988: 7.0166, 2031: 7.0166, 7650: 7.9329, 13423: 97.0}))]\n",
    " \n",
    " res.select('rawPrediction').take(2)\n",
    "[Row(rawPrediction=DenseVector([-1060.7325, -1136.7546])),\n",
    " Row(rawPrediction=DenseVector([-803.1362, -866.6127]))]\n",
    " \n",
    " res.select('probability').take(2)\n",
    "[Row(probability=DenseVector([1.0, 0.0])),\n",
    " Row(probability=DenseVector([1.0, 0.0]))]\n",
    " \n",
    " class_probabilities = pred.pi\n",
    "feature_probabilities = pred.theta\n",
    "class_probabilities,feature_probabilities\n",
    "\n",
    "(DenseVector([-0.1445, -2.0057]),\n",
    " DenseMatrix(2, 13424, [-5.7851, -7.0796, -6.6062, -6.0544, -6.689, -6.627, -6.4445, -6.6828, ..., -11.8623, -11.8623, -11.8623, -11.8623, -11.8623, -9.6726, -11.8623, -0.6525], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use logistic regression,DecisionTreeClassifier, RandomForestClassifier,GBTClassifier and check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy is 95.28848387140773\n",
      "lr_with_params accuracy is 50.0\n",
      "NaiveBayes accuracy is 18.28180290464936\n",
      "DecisionTreeClassifier accuracy is 48.964381839793425\n",
      "GradientBoostClassifier accuracy is 97.34708237126499\n",
      "RandomForestClassifier accuracy is 93.43550612763516\n",
      "LogisticRegression accuracy is 87.5\n",
      "lr_with_params accuracy is 50.0\n",
      "NaiveBayes accuracy is 94.36746000300575\n",
      "DecisionTreeClassifier accuracy is 80.28073039771563\n",
      "GradientBoostClassifier accuracy is 83.65502848633068\n",
      "RandomForestClassifier accuracy is 50.0\n",
      "LogisticRegression accuracy is 96.46661770212962\n",
      "lr_with_params accuracy is 80.51199958122098\n",
      "NaiveBayes accuracy is 92.66021977210805\n",
      "DecisionTreeClassifier accuracy is 93.37090926376854\n",
      "GradientBoostClassifier accuracy is 94.54026726766364\n",
      "RandomForestClassifier accuracy is 80.51199958122098\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes,LogisticRegression,DecisionTreeClassifier, RandomForestClassifier,GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator \n",
    "def build_model(evaluator):\n",
    "    models=[]\n",
    "    models.append(('LogisticRegression',LogisticRegression()))\n",
    "    models.append(('lr_with_params',LogisticRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)))\n",
    "    models.append(('NaiveBayes',NaiveBayes()))\n",
    "    models.append(('DecisionTreeClassifier',DecisionTreeClassifier()))\n",
    "    models.append(('GradientBoostClassifier',GBTClassifier()))\n",
    "    models.append(('RandomForestClassifier',RandomForestClassifier()))\n",
    "    for name,model in models:\n",
    "        pred=model.fit(train)    \n",
    "        result=pred.transform(test)\n",
    "        accuracy=evaluator.evaluate(result)\n",
    "        print(f\"{name} accuracy is {accuracy*100}\")\n",
    "\n",
    "uni_bin=build_model(BinaryClassificationEvaluator())\n",
    "uni_bin_param=build_model(BinaryClassificationEvaluator().setLabelCol(\"label\").setRawPredictionCol(\"prediction\").setMetricName(\"areaUnderROC\"))\n",
    "uni_mul=build_model(MulticlassClassificationEvaluator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8875938854992451\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 50, 100]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=rf,\n",
    "                    estimatorParamMaps=param_grid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5,\n",
    "                    seed=42)\n",
    "cv_model = cv.fit(train)\n",
    "best_model = cv_model.bestModel\n",
    "predictions = best_model.transform(test)\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|spam|             message|length|label|          token_text|         stop_tokens|              ngrams|               c_vec|              tf_idf|            features|\n",
      "+----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|[go jurong, juron...|(36668,[8357,9892...|(36668,[8357,9892...|(36669,[8357,9892...|\n",
      "| ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|[ok lar..., lar.....|(36668,[13150,136...|(36668,[13150,136...|(36669,[13150,136...|\n",
      "|spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|[free entry, entr...|(36668,[44,56,113...|(36668,[44,56,113...|(36669,[44,56,113...|\n",
      "| ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|[u dun, dun say, ...|(36668,[73,155,44...|(36668,[73,155,44...|(36669,[73,155,44...|\n",
      "| ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|[nah think, think...|(36668,[10516,193...|(36668,[10516,193...|(36669,[10516,193...|\n",
      "+----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "LogisticRegression accuracy is 87.46806388589067\n",
      "lr_with_params accuracy is 50.0\n",
      "NaiveBayes accuracy is 17.92913939857638\n",
      "DecisionTreeClassifier accuracy is 85.89397210115722\n",
      "GradientBoostClassifier accuracy is 93.1333939037886\n",
      "RandomForestClassifier accuracy is 72.99024496878117\n",
      "LogisticRegression accuracy is 80.18867924528301\n",
      "lr_with_params accuracy is 50.0\n",
      "NaiveBayes accuracy is 63.432295438088346\n",
      "DecisionTreeClassifier accuracy is 83.01152432609675\n",
      "GradientBoostClassifier accuracy is 71.22641509433963\n",
      "RandomForestClassifier accuracy is 50.0\n",
      "LogisticRegression accuracy is 94.15336873738899\n",
      "lr_with_params accuracy is 80.51199958122098\n",
      "NaiveBayes accuracy is 40.650280843979665\n",
      "DecisionTreeClassifier accuracy is 89.003769845311\n",
      "GradientBoostClassifier accuracy is 90.95656369881081\n",
      "RandomForestClassifier accuracy is 80.51199958122098\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "tokenizer=Tokenizer(inputCol=\"message\",outputCol=\"token_text\")\n",
    "stop_word_remover=StopWordsRemover(inputCol=\"token_text\",outputCol=\"stop_tokens\")\n",
    "ngram = NGram().setN(2).setInputCol(\"stop_tokens\").setOutputCol(\"ngrams\")\n",
    "cv_ngram_model = CountVectorizer().setInputCol(\"ngrams\").setOutputCol(\"c_vec\")\n",
    "idf=IDF(inputCol=\"c_vec\",outputCol=\"tf_idf\")\n",
    "ham_spam_to_num=StringIndexer(inputCol=\"spam\",outputCol=\"label\")\n",
    "cleaned=VectorAssembler(inputCols=['tf_idf','length'],outputCol=\"features\")\n",
    "\n",
    "pipeline1=Pipeline(stages=[ham_spam_to_num,tokenizer,stop_word_remover,ngram,cv_ngram_model,idf,cleaned])\n",
    "cleaner1=pipeline1.fit(df)\n",
    "clean_df1=cleaner1.transform(df)\n",
    "clean_df1.show(5)\n",
    "\n",
    "clean_df1=clean_df1.select(['label','features'])\n",
    "(train,test)=clean_df1.randomSplit([0.7,0.3],seed=42)\n",
    "\n",
    "\n",
    "big_bin=build_model(BinaryClassificationEvaluator())\n",
    "big_bin_param=build_model(BinaryClassificationEvaluator().setLabelCol(\"label\").setRawPredictionCol(\"prediction\").setMetricName(\"areaUnderROC\"))\n",
    "big_mul=build_model(MulticlassClassificationEvaluator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|spam|             message|length|label|          token_text|         stop_tokens|              ngrams|               c_vec|              tf_idf|            features|\n",
      "+----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|[go jurong point,...|(36208,[5516,5797...|(36208,[5516,5797...|(36209,[5516,5797...|\n",
      "| ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|[ok lar... joking...|(36208,[9744,9906...|(36208,[9744,9906...|(36209,[9744,9906...|\n",
      "|spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|[free entry 2, en...|(36208,[21,1534,1...|(36208,[21,1534,1...|(36209,[21,1534,1...|\n",
      "| ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|[u dun say, dun s...|(36208,[5341,5736...|(36208,[5341,5736...|(36209,[5341,5736...|\n",
      "| ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|[nah think goes, ...|(36208,[21106,265...|(36208,[21106,265...|(36209,[21106,265...|\n",
      "+----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "LogisticRegression accuracy is 74.2733253179949\n",
      "lr_with_params accuracy is 50.0\n",
      "NaiveBayes accuracy is 15.382618556419345\n",
      "DecisionTreeClassifier accuracy is 83.93152350634625\n",
      "GradientBoostClassifier accuracy is 92.63454155452024\n",
      "RandomForestClassifier accuracy is 59.43396226415094\n",
      "LogisticRegression accuracy is 79.24528301886792\n",
      "lr_with_params accuracy is 50.0\n",
      "NaiveBayes accuracy is 61.259956553222295\n",
      "DecisionTreeClassifier accuracy is 76.27744456437091\n",
      "GradientBoostClassifier accuracy is 77.52910114355198\n",
      "RandomForestClassifier accuracy is 50.0\n",
      "LogisticRegression accuracy is 93.83771418502313\n",
      "lr_with_params accuracy is 80.51199958122098\n",
      "NaiveBayes accuracy is 35.64586152886221\n",
      "DecisionTreeClassifier accuracy is 88.73730089722646\n",
      "GradientBoostClassifier accuracy is 89.2036948555686\n",
      "RandomForestClassifier accuracy is 80.51199958122098\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer=Tokenizer(inputCol=\"message\",outputCol=\"token_text\")\n",
    "transformed = tokenizer.transform(df)\n",
    "#transformed.show(1)\n",
    "\n",
    "stop_word_remover=StopWordsRemover(inputCol=\"token_text\",outputCol=\"stop_tokens\")\n",
    "stop_word_transformed = stop_word_remover.transform(transformed)\n",
    "#stop_word_transformed.show(1)\n",
    "\n",
    "ngram = NGram().setN(3).setInputCol(\"stop_tokens\").setOutputCol(\"ngrams\")\n",
    "ngramDataFrame = ngram.transform(stop_word_transformed)\n",
    "#ngramDataFrame.select(\"ngrams\").show(2, False)\n",
    "\n",
    "cv_ngram_model = CountVectorizer().setInputCol(\"ngrams\").setOutputCol(\"c_vec\").fit(ngramDataFrame)\n",
    "cv_featured = cv_ngram_model.transform(ngramDataFrame)\n",
    "#cv_featured.show(1)\n",
    "\n",
    "idf=IDF(inputCol=\"c_vec\",outputCol=\"tf_idf\")\n",
    "ham_spam_to_num=StringIndexer(inputCol=\"spam\",outputCol=\"label\")\n",
    "cleaned=VectorAssembler(inputCols=['tf_idf','length'],outputCol=\"features\")\n",
    "\n",
    "pipeline1=Pipeline(stages=[ham_spam_to_num,tokenizer,stop_word_remover,ngram,cv_ngram_model,idf,cleaned])\n",
    "cleaner1=pipeline1.fit(df)\n",
    "clean_df1=cleaner1.transform(df)\n",
    "clean_df1.show(5)\n",
    "\n",
    "clean_df1=clean_df1.select(['label','features'])\n",
    "(train,test)=clean_df1.randomSplit([0.7,0.3],seed=42)\n",
    "\n",
    "\n",
    "tri_bin=build_model(BinaryClassificationEvaluator())\n",
    "trin_bin_param=build_model(BinaryClassificationEvaluator().setLabelCol(\"label\").setRawPredictionCol(\"prediction\").setMetricName(\"areaUnderROC\"))\n",
    "tri_mul=build_model(MulticlassClassificationEvaluator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "tokenizer=Tokenizer(inputCol=\"message\",outputCol=\"token_text\")\n",
    "stop_word_remover=StopWordsRemover(inputCol=\"token_text\",outputCol=\"stop_tokens\")\n",
    "#stopwords = StopWordsRemover().getStopWords() + [\"-\"] less accuracy on having this\n",
    "#stop_word_remover = StopWordsRemover().setStopWords(stopwords).setInputCol(\"token_text\").setOutputCol(\"stop_tokens\")\n",
    "count_vec=CountVectorizer(inputCol=\"stop_tokens\",outputCol=\"c_vec\") # you can use hashdocumentfrequency\n",
    "idf=IDF(inputCol=\"c_vec\",outputCol=\"tf_idf\")\n",
    "ham_spam_to_num=StringIndexer(inputCol=\"spam\",outputCol=\"label\")\n",
    "cleaned=VectorAssembler(inputCols=['tf_idf','length'],outputCol=\"features\")\n",
    "lr=LogisticRegression()\n",
    "pipeline=Pipeline(stages=[ham_spam_to_num,tokenizer,stop_word_remover,count_vec,idf,cleaned,lr])\n",
    "cleaner=pipeline.fit(df)\n",
    "cleaner.write().overwrite().save(\"/user/raghavendr48edu/spam_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_a74d373ce022"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = PipelineModel.load(\"/user/raghavendr48edu/spam_model\")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
